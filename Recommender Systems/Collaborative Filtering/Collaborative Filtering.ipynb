{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664f1be4",
   "metadata": {},
   "source": [
    "# Recommender Systems Using Collaborative Filtering\n",
    "\n",
    "> *Recommender Systems*  \n",
    "> *MSc in Data Science, Department of Informatics*  \n",
    "> *Athens University of Economics and Business*\n",
    "\n",
    "---\n",
    "\n",
    "Find a ***rating-based*** or ***matching-based*** dataset that can be used to inform a recommender system based on ***collaborative filtering***.\n",
    "\n",
    "Build a Python notebook that:\n",
    "\n",
    "- Loads the dataset\n",
    "- Tries at least 2 different recommendations methods based on collaborative filtering (e.g., Count-based, Matrix Factorization, Tensorflow)\n",
    "- Uses quantitative metrics to evaluate the recommendations of each of the methods that you selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b78427",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### *Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8140118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d060157",
   "metadata": {},
   "source": [
    "### *Data*\n",
    "\n",
    "- The dataset that will be used can be found in the following link: https://www.kaggle.com/datasets/tamber/steam-video-games\n",
    "- The data are taken from Steam which is a gaming platform \n",
    "- It is a list of user behaviors, with columns: user-id, game-title, behavior-name, value. \n",
    "- The behaviors included are 'purchase' and 'play'. \n",
    "- The value indicates the degree to which the behavior was performed - in the case of 'purchase' the value is always 1, and in the case of 'play' the value represents the number of hours the user has played the game.\n",
    "\n",
    "##### *Read ratings data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf4ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_games(path: str):\n",
    "    \n",
    "    games_df = pd.read_csv(path, header = None, usecols = [0,1,2,3] ,\n",
    "                       names = ['userId','Game','Behavior', 'Value'])\n",
    "    \n",
    "    # Checking for Duplicate rows and droping them\n",
    "    if (games_df.duplicated() == True).sum() > 0:\n",
    "        games_df.drop(games_df.index[games_df.duplicated() == True].tolist(), inplace = True)\n",
    "        \n",
    "    return games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e65a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>Game</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Spore</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId                        Game  Behavior  Value\n",
       "0  151603712  The Elder Scrolls V Skyrim  purchase    1.0\n",
       "1  151603712  The Elder Scrolls V Skyrim      play  273.0\n",
       "2  151603712                   Fallout 4  purchase    1.0\n",
       "3  151603712                   Fallout 4      play   87.0\n",
       "4  151603712                       Spore  purchase    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = load_games(os.getcwd() + '\\\\' + 'steam-200k.csv')\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f2b8c",
   "metadata": {},
   "source": [
    "## Recommendations Using Item-Based Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe993b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct users set\n",
    "distinct_users=set(games_df['userId'])\n",
    "\n",
    "#distinct games\n",
    "distinct_games = set(games_df['Game'].unique())\n",
    "\n",
    "#creating unique games dictionary\n",
    "games_dict = dict(zip(distinct_games,[i for i in range(len(distinct_games))]))\n",
    "\n",
    "#replacing games with their id instead of their title\n",
    "games_df['Game'] = games_df['Game'].map(games_dict)\n",
    "\n",
    "#reversing keys and values of the games dictionary\n",
    "games_dict = dict((v,k) for k,v in games_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cfb88",
   "metadata": {},
   "source": [
    "##### *Function to get the ratings of each user*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e82ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings(distinct_users: dict\n",
    "                    , games_df: pd.core.frame.DataFrame):\n",
    "\n",
    "    '''\n",
    "    Loads all games purchased and/or played by each user\n",
    "\n",
    "    Each game is mapped to the following two ratings:\n",
    "        \n",
    "        P-P -> if the game was purchased and played\n",
    "    \n",
    "        P-NP -> if the game was purchased and not played\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    user_ratings = {}\n",
    "\n",
    "    for user in distinct_users:\n",
    "\n",
    "        purchased = games_df[(games_df['userId'] == user) & (games_df['Behavior'] == 'purchase')]['Game'].values.tolist()\n",
    "\n",
    "        played = games_df[(games_df['userId'] == user) & (games_df['Behavior'] == 'play')]['Game'].values.tolist()\n",
    "\n",
    "        user_ratings[user] = dict(zip([game for game in purchased],\n",
    "                                      ['P-P' if game in played else 'P-NP' for game in purchased]))\n",
    "        \n",
    "    return user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e4dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute\n",
    "user_ratings = get_user_ratings(distinct_users,games_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c686124",
   "metadata": {},
   "source": [
    "##### *Function to get user neighbors based on the Jaccard Similarity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74d7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_neighbors(user_ratings:dict, # games purchased/played by each user\n",
    "                       min_rating_num:int=5 # at least this many games purchased/played are required for a comparison\n",
    "                      ):\n",
    "    \n",
    "    '''\n",
    "    Compute rating-based similarity between every two pairs of users \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #get all possible pairs of users\n",
    "    pairs=list(combinations(list(user_ratings.keys()),2))\n",
    "    \n",
    "    usim=defaultdict(dict) # initialize the sim dictionary\n",
    "    \n",
    "    for u1,u2 in pairs: # for every user pair \n",
    "   \n",
    "        #get a set with all the discretized values (game, purchased/played values) for u1 and u2\n",
    "        s1=set([(mid,pol) for mid,pol in user_ratings[u1].items()])\n",
    "        s2=set([(mid,pol) for mid,pol in user_ratings[u2].items()])\n",
    "\n",
    "        # check if both users respect the lower bound\n",
    "        if len(s1)<min_rating_num or len(s2)<min_rating_num: continue\n",
    "      \n",
    "        # get the union and intersection for these two users\n",
    "        union=s1.union(s2)\n",
    "        inter=s1.intersection(s2)\n",
    "    \n",
    "        # compute user sim via the jaccard coeff\n",
    "        jacc=len(inter)/len(union)\n",
    "\n",
    "        # remember the sim values\n",
    "        usim[u1][u2]=jacc\n",
    "        usim[u2][u1]=jacc\n",
    "        \n",
    "    # attach each user to its neighbors, sorted by sim in descending order \n",
    "    return {user:sorted(usim[user].items(),key=lambda x:x[1], reverse=True) for user in usim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c461f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute\n",
    "neighbors_u=get_user_neighbors(user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257da46f",
   "metadata": {},
   "source": [
    "##### *Function to get precision and recall*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a24d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(actual_ratings, recommendations):\n",
    "    true_positives = len(set(actual_ratings).intersection(recommendations))\n",
    "    precision = true_positives / len(recommendations) if len(recommendations) > 0 else 0\n",
    "    recall = true_positives / len(actual_ratings) if len(actual_ratings) > 0 else 0\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cabf10",
   "metadata": {},
   "source": [
    "##### *Recommendations*\n",
    "\n",
    "The function provides user-based recommendations for a given user by following these steps:\n",
    "\n",
    "  - Identifies the most similar users to the specified user.\n",
    "  - Iterates through all games purchased or played by the neighbors.\n",
    "  - Assigns a score of +2 to each game if a neighbor purchased and played it, and +1 if the neighbor only purchased it.\n",
    "  - Scales the votes based on user similarity.\n",
    "  - Sorts the games in descending order based on their scores.\n",
    "  - Iterates through the sorted list of games. If the user has already rated a game, stores its rating; otherwise, prints the game.\n",
    "  \n",
    "The evaluation metrics used are the following:\n",
    "- **Number of Games Before First Valid Recommendation:**\n",
    "  - Represents the count of games iterated before the first valid recommendation.\n",
    "  - Indicates how many games were considered before identifying a game that the user has not yet rated.\n",
    "\n",
    "- **Number of Games per Valid Recommendation:**\n",
    "  - Signifies the average number of games considered for each valid recommendation.\n",
    "  - Provides insight into the efficiency of the recommendation process.\n",
    "\n",
    "- **Recommendations Accuracy:**\n",
    "  - Presents the accuracy of the recommendations as a percentage.\n",
    "  - Calculated by dividing the number of already rated games by the total number of games considered for recommendations.\n",
    "  - Reflects the proportion of recommendations that align with the user's preferences.\n",
    "\n",
    "- **Precision:**\n",
    "  - Precision is the ratio of relevant recommendations to the total recommendations made.\n",
    "  - In this context, it measures how many of the recommended games were actually liked by the user.\n",
    "\n",
    "- **Recall:**\n",
    "  - Recall is the ratio of relevant recommendations to the total number of relevant items.\n",
    "  - In this context, it measures how many of the user's liked games were successfully recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ee2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_evaluate_ub(user:int, \n",
    "                 games_dict:dict, # games dict  \n",
    "                 neighbors_u:dict, # neighbors dict\n",
    "                 user_ratings:dict, # ratings submitted per user \n",
    "                 neighbor_num:int, # number of neighbors to consider\n",
    "                 rec_num:int,# number of games to recommend\n",
    "                 show_rec: bool = False, #determine whether to show recommendations or not\n",
    "                 show_eval: bool = False #determine whether to show evaluation metrics\n",
    "                ):\n",
    "    \n",
    "    if user not in neighbors_u or len(neighbors_u[user]) < neighbor_num:\n",
    "        if show_rec:\n",
    "            print(\"Not enough neighbors to provide recommendations.\")\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    top_k=neighbors_u[user][:neighbor_num] # get the top k neighbors of this user\n",
    "    \n",
    "    votes=defaultdict(int) # count the values per game\n",
    "    \n",
    "    for neighbor,sim_val in top_k: # for each neighbor \n",
    "\n",
    "        for mid,pol in user_ratings[neighbor].items(): # for each game purchased/played by this neighbor\n",
    "\n",
    "            if pol=='P-P': \n",
    "                votes[mid]+=2*sim_val\n",
    "            else: \n",
    "                votes[mid]+=1*sim_val\n",
    "\n",
    "    # sort the games in descending order \n",
    "    srt=sorted(votes.items(),key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    if show_rec: \n",
    "        print('\\nI suggest the following games because they have received positive ratings from users who tend to like what you like:\\n')\n",
    "        print('='*100)\n",
    "          \n",
    "    cnt=0 # count number of recommendations made \n",
    "    total = 0 # total number of games before reaching k recommendations\n",
    "    first_rating_index = 0 # number of recommendations before first unrated game\n",
    "    \n",
    "    already_rated={}\n",
    "    \n",
    "    for gm, score in srt: # for each game \n",
    "    \n",
    "        total += 1\n",
    "        \n",
    "        title=games_dict[gm] # get the title \n",
    "        \n",
    "        rat=user_ratings[user].get(gm,None) # check if the user has already purchased/played the game \n",
    "        \n",
    "        if rat: # game already rated \n",
    "            already_rated[title]=rat # store the value\n",
    "            continue\n",
    "     \n",
    "        cnt+=1 # one more recommendation\n",
    "        if first_rating_index == 0 : first_rating_index = len(already_rated)\n",
    "        \n",
    "        if show_rec: print('\\n',gm, title) # print \n",
    "    \n",
    "        if cnt==rec_num:break # stop once you 've made enough recommendations\n",
    "    \n",
    "    #if show_rec: print('\\n',already_rated)\n",
    "        \n",
    "    if show_eval:\n",
    "        precision, recall = calculate_precision_recall(list(user_ratings[user].values()), list(already_rated.values()))\n",
    "        print(\"\\n\")\n",
    "        print(\"Evaluation Metrics for Current Recommendation:\")\n",
    "        print('='*100)\n",
    "        #print(\"\\n\")\n",
    "        print('Number of Games Before First Valid Recommendation: ', first_rating_index)\n",
    "        print('Number of Games per Valid Recommendation: ', round(total / rec_num,2))\n",
    "        print('Recommendations Accuracy: ', \"{:0.2%}\".format(len(already_rated) / len(user_ratings[user]),2))\n",
    "        print('Precision: ',\"{:0.2%}\".format(precision))\n",
    "        print('Recall: ',\"{:0.2%}\".format(recall))\n",
    "        \n",
    "    return first_rating_index, total, len(already_rated), already_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e4dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I suggest the following games because they have received positive ratings from users who tend to like what you like:\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " 1375 Dota 2\n",
      "\n",
      " 4863 Deathmatch Classic\n",
      "\n",
      " 3821 Day of Defeat\n",
      "\n",
      " 1005 Counter-Strike Source\n",
      "\n",
      " 1968 Ricochet\n",
      "\n",
      " 2052 War Thunder\n",
      "\n",
      " 3877 No More Room in Hell\n",
      "\n",
      " 1860 Counter-Strike Nexon Zombies\n",
      "\n",
      " 1208 Call of Duty Modern Warfare 2 - Multiplayer\n",
      "\n",
      " 384 Call of Duty Modern Warfare 2\n",
      "\n",
      "\n",
      "Evaluation Metrics for Current Recommendation:\n",
      "====================================================================================================\n",
      "Number of Games Before First Valid Recommendation:  4\n",
      "Number of Games per Valid Recommendation:  1.4\n",
      "Recommendations Accuracy:  66.67%\n",
      "Precision:  50.00%\n",
      "Recall:  33.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " 14,\n",
       " 4,\n",
       " {'Counter-Strike': 'P-P',\n",
       "  'Counter-Strike Global Offensive': 'P-P',\n",
       "  'Counter-Strike Condition Zero Deleted Scenes': 'P-P',\n",
       "  'Counter-Strike Condition Zero': 'P-NP'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_evaluate_ub(91687359, games_dict, neighbors_u, user_ratings, 15, 10, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27243a",
   "metadata": {},
   "source": [
    "##### *Function to get the evaluation metrics on a subset of users*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87bc1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ub_recs(user_subset: list, #list of users that will participate in the evaluation\n",
    "                    games_dict:dict, # game info  \n",
    "                    neighbors_u:dict, # neighbors dict\n",
    "                    user_ratings:dict, # values submitted per user \n",
    "                    neighbor_num:int, # number of neighbors to consider\n",
    "                    rec_num:int,# number of games to recommend\n",
    "                    show_eval: bool = True\n",
    "                    ):\n",
    "    \n",
    "    indexes = [] #list that holds the count before the first recommendation\n",
    "    total_recs = [] #list that holds the number of total recommendations / number of games to recommend\n",
    "    rated = [] #list that holds the already rated / purchase and/or played games\n",
    "    precision_list = []  # List that holds precision values\n",
    "    recall_list = []  # List that holds recall values\n",
    "    \n",
    "    for user in user_subset:\n",
    "        \n",
    "        if user in neighbors_u:\n",
    "            f, c, s, already_rated =  recommend_evaluate_ub(user, games_dict, neighbors_u, user_ratings, 15, 10, False, False)\n",
    "            indexes.append(f)\n",
    "            total_recs.append(c / rec_num)\n",
    "            rated.append(round(s / len(user_ratings[user]), 2))\n",
    "            \n",
    "            # Calculate precision and recall for each user\n",
    "            precision, recall = calculate_precision_recall(list(user_ratings[user].values()), list(already_rated.values()))\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "\n",
    "    if show_eval:\n",
    "        print('Average Number of Games Before First Valid Recommendation: ', round(sum(indexes) / len(indexes),2))\n",
    "        print('Average Number of Games per Valid Recommendation: ', round(sum(total_recs) / len(total_recs),2))\n",
    "        print('Recommendations Accuracy: ', \"{:0.2%}\".format(sum(rated) / len(rated),2))\n",
    "        print('Average Precision: ', \"{:0.2%}\".format(sum(precision_list) / len(precision_list), 2))\n",
    "        print('Average Recall: ', \"{:0.2%}\".format(sum(recall_list) / len(recall_list), 2))\n",
    "        \n",
    "    return indexes,total_recs,rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8ed6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Games Before First Valid Recommendation:  5.15\n",
      "Average Number of Games per Valid Recommendation:  2.02\n",
      "Recommendations Accuracy:  57.75%\n",
      "Average Precision:  25.25%\n",
      "Average Recall:  15.10%\n"
     ]
    }
   ],
   "source": [
    "# number of items to select (15% of list size)\n",
    "num_items_to_select = int(len(distinct_users) * 0.15)\n",
    "\n",
    "# select a random subset of items\n",
    "random_subset = random.sample(distinct_users, num_items_to_select)\n",
    "\n",
    "ind, cnt, pr = evaluate_ub_recs(random_subset, games_dict, neighbors_u, user_ratings, 15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f7244",
   "metadata": {},
   "source": [
    "## Recommendations Using Matrix Factorization\n",
    "\n",
    "### *Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3cd99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection.validation import cross_validate\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5645f1b",
   "metadata": {},
   "source": [
    "##### *Scaling Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a18f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_value(value, in_min, in_max, out_min, out_max):\n",
    "    \"\"\"\n",
    "    Scales a value from one range to another.\n",
    "\n",
    "    Parameters:\n",
    "    value (float): the value to be scaled.\n",
    "    in_min (float): the minimum value of the input range.\n",
    "    in_max (float): the maximum value of the input range.\n",
    "    out_min (float): the minimum value of the output range.\n",
    "    out_max (float): the maximum value of the output range.\n",
    "\n",
    "    Returns:\n",
    "    float: the scaled value.\n",
    "    \"\"\"\n",
    "    if in_min == in_max and out_min <= value <= out_max:\n",
    "        return value\n",
    "    elif in_min == in_max and value >= out_max:\n",
    "        in_max += 0.1\n",
    "        return (value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "    else:\n",
    "        return (value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ad702",
   "metadata": {},
   "source": [
    "### *Data Preprocessing*\n",
    "\n",
    "Given the original dataset this function does the following:\n",
    "\n",
    "- Creates a copy of the original dataset and keeps only the games that were purchased by each user\n",
    "- Merges the dataset with another that containes the corresponding playing time\n",
    "- Updates the value column, which now is the sum of purchase value (1) and playing time\n",
    "- Scales that value in the range of (1,5) so that it can be used by the surprise library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70a373ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(games_df: pd.core.frame.DataFrame,  # games dataframe\n",
    "                    distinct_users: dict  # distinct users\n",
    "                    ):\n",
    "    \n",
    "    # Select only purchased games\n",
    "    games_df_mt = games_df[games_df['Behavior'] == 'purchase'].copy()\n",
    "    \n",
    "    # calculate the total playing time of each game per user and then merge with the dataframe above\n",
    "    games_df_mt = games_df_mt.merge(\n",
    "        games_df[games_df['Behavior'] == 'play'].groupby(['userId', 'Game'], as_index=False)['Value'].sum(),\n",
    "        how='left', left_on=['userId', 'Game'], right_on=['userId', 'Game']\n",
    "    )\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    games_df_mt.Value_y.fillna(0, inplace=True)\n",
    "\n",
    "    # Create a new 'Value' column by adding playing and purchase\n",
    "    games_df_mt['Value'] = games_df_mt['Value_x'] + games_df_mt['Value_y']\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    games_df_mt.drop(['Value_x', 'Value_y', 'Behavior'], axis=1, inplace=True)\n",
    "\n",
    "    # Initialize 'Scaled_Value' with 'Value'\n",
    "    games_df_mt['Scaled_Value'] = games_df_mt['Value']\n",
    "\n",
    "    # Scale 'Scaled_Value' for each user within the range [1, 5]\n",
    "    for user in distinct_users:\n",
    "        mn = games_df_mt[games_df_mt['userId'] == user].Value.min()\n",
    "        mx = games_df_mt[games_df_mt['userId'] == user].Value.max()\n",
    "\n",
    "        games_df_mt.loc[games_df_mt['userId'] == user, 'Scaled_Value'] = games_df_mt[\n",
    "            games_df_mt['userId'] == user].Scaled_Value.apply(\n",
    "            lambda x: scale_value(x, mn, mx, 1, 5))\n",
    "\n",
    "    return games_df_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d50a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>Game</th>\n",
       "      <th>Value</th>\n",
       "      <th>Scaled_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151603712</td>\n",
       "      <td>3571</td>\n",
       "      <td>274.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151603712</td>\n",
       "      <td>3031</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.274725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151603712</td>\n",
       "      <td>3980</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1.218315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151603712</td>\n",
       "      <td>1839</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.177289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151603712</td>\n",
       "      <td>3505</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.130403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  Game  Value  Scaled_Value\n",
       "0  151603712  3571  274.0      5.000000\n",
       "1  151603712  3031   88.0      2.274725\n",
       "2  151603712  3980   15.9      1.218315\n",
       "3  151603712  1839   13.1      1.177289\n",
       "4  151603712  3505    9.9      1.130403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute\n",
    "games_df_mt = preprocess_data(games_df,distinct_users)\n",
    "games_df_mt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a338c6c",
   "metadata": {},
   "source": [
    "##### *Recommendations Model Definition*\n",
    "\n",
    "- Given the dataset with the scaled playing time, this function creates the model with which we are going to make our recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c730c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(df: pd.core.frame.DataFrame,\n",
    "                 lower_bound: float, #lower bound of surprize library\n",
    "                 upper_bound: float,  #upper bound of surprize library\n",
    "                 factors_num: int    #number of factors to keep in SVD\n",
    "                ):\n",
    "    \n",
    "    # Load Reader library\n",
    "    reader = Reader(rating_scale=(lower_bound, upper_bound))\n",
    "\n",
    "    # Load games dataset with Dataset library\n",
    "    data = Dataset.load_from_df(df[['userId', 'Game', 'Scaled_Value']], reader)\n",
    "    \n",
    "    # Use the SVD algorithm.\n",
    "    svd = SVD(n_factors = factors_num)\n",
    "\n",
    "    # Compute the RMSE of the SVD algorithm.\n",
    "    cross_validate(svd, data, measures=['RMSE'],cv=10,verbose=True)\n",
    "    \n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    svd.fit(trainset)# fit the svd\n",
    "    \n",
    "    return svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72cd6d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.8412  0.8650  0.8439  0.8672  0.8614  0.8622  0.8477  0.8699  0.8570  0.8492  0.8565  0.0097  \n",
      "Fit time          0.93    0.97    0.94    0.98    0.97    0.99    1.00    0.96    1.00    1.04    0.98    0.03    \n",
      "Test time         0.37    0.06    0.06    0.06    0.06    0.33    0.06    0.07    0.06    0.05    0.12    0.12    \n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "svd = define_model(games_df_mt,1,5,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799abcf5",
   "metadata": {},
   "source": [
    "##### *Make Recommendations*\n",
    "\n",
    "The recommendations function follows the steps below:\n",
    "\n",
    "- Extract historical ratings for the user.\n",
    "- Use the collaborative filtering model to predict ratings for all games.\n",
    "- Identify games that the user has not rated.\n",
    "- Recommend the top-rated unrated games up to the specified number.\n",
    "- Compile the recommendations into a DataFrame with Game IDs, Titles, and Predicted Ratings.\n",
    "- Sort the DataFrame by predicted ratings in descending order.\n",
    "- Return the sorted DataFrame as the final set of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7004d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_surprise(uid:int,\n",
    "              ratings_df:pd.core.frame.DataFrame,\n",
    "              model,\n",
    "              games_dict:dict,\n",
    "              rec_num:int\n",
    "             ):\n",
    "\n",
    "    #get all the values by this user\n",
    "    my_ratings=ratings_df[ratings_df.userId==uid]\n",
    "\n",
    "    #zip the values into a dict\n",
    "    already_rated=dict(zip(my_ratings.Game,my_ratings.Scaled_Value))\n",
    "\n",
    "    pred_dict={}# store predicted values\n",
    "\n",
    "    for game in games_dict: # for every game \n",
    "\n",
    "        pred_dict[game]=model.predict(uid = uid,iid = game).est# get the pred for this user\n",
    "        \n",
    "    # sort the games by predicted values\n",
    "    srt=sorted(pred_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    rec_set=set()# set of games to be recommended\n",
    "\n",
    "    total = 0 # total number of games before reaching k recommendations\n",
    "    first_rating_index = 0 # number of recommendations before first non purchased/played game\n",
    "    \n",
    "    for mid,pred in srt:\n",
    "        \n",
    "        total += 1\n",
    "        \n",
    "        if mid not in already_rated: # game has not already been purchased/played\n",
    "            \n",
    "            if first_rating_index == 0 : first_rating_index = total\n",
    "            \n",
    "            rec_set.add(mid) # add to the set\n",
    "            \n",
    "            if len(rec_set)==rec_num:break \n",
    "       \n",
    "    # make a data frame with only the recommended games \n",
    "    \n",
    "    rec_df = pd.DataFrame({'GameId': [game for game in games_dict.keys() if game in rec_set],\n",
    "              'Title': [games_dict[game] for game in games_dict.keys() if game in rec_set]})\n",
    "    \n",
    "    #add the predicted rating as a new column\n",
    "    rec_df['predicted_rating'] = rec_df['GameId'].map(pred_dict)\n",
    "    \n",
    "    #sort the df by the new column\n",
    "    rec_df=rec_df.sort_values(['predicted_rating'], ascending=False)\n",
    "    \n",
    "    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d56f586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>Title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238</td>\n",
       "      <td>Football Manager 2012</td>\n",
       "      <td>3.105558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1208</td>\n",
       "      <td>Call of Duty Modern Warfare 2 - Multiplayer</td>\n",
       "      <td>2.770490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4905</td>\n",
       "      <td>Total War ROME II - Emperor Edition</td>\n",
       "      <td>2.412587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4969</td>\n",
       "      <td>Football Manager 2013</td>\n",
       "      <td>2.386558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1318</td>\n",
       "      <td>F1 2012</td>\n",
       "      <td>2.361092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>974</td>\n",
       "      <td>Football Manager 2014</td>\n",
       "      <td>2.343981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2788</td>\n",
       "      <td>Counter-Strike Global Offensive</td>\n",
       "      <td>2.317203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5128</td>\n",
       "      <td>Football Manager 2011</td>\n",
       "      <td>2.306468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4133</td>\n",
       "      <td>Football Manager 2010</td>\n",
       "      <td>2.186282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884</td>\n",
       "      <td>Football Manager 2015</td>\n",
       "      <td>2.093617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GameId                                        Title  predicted_rating\n",
       "0     238                        Football Manager 2012          3.105558\n",
       "2    1208  Call of Duty Modern Warfare 2 - Multiplayer          2.770490\n",
       "7    4905          Total War ROME II - Emperor Edition          2.412587\n",
       "8    4969                        Football Manager 2013          2.386558\n",
       "3    1318                                      F1 2012          2.361092\n",
       "1     974                        Football Manager 2014          2.343981\n",
       "5    2788              Counter-Strike Global Offensive          2.317203\n",
       "9    5128                        Football Manager 2011          2.306468\n",
       "6    4133                        Football Manager 2010          2.186282\n",
       "4    1884                        Football Manager 2015          2.093617"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_surprise(109205612,\n",
    "              games_df_mt,\n",
    "              svd,\n",
    "              games_dict,\n",
    "              10\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e6977",
   "metadata": {},
   "source": [
    "##### *Evaluate Recommendations*\n",
    "\n",
    "Certainly! The following function is designed to evaluate the performance of the recommendation model in predicting playing time for games. Here's a brief description of the evaluation measures used:\n",
    "\n",
    "- **Root Mean Squared Error (RMSE):**\n",
    "  - **Definition:** The square root of the average of the squared differences between actual and predicted values.\n",
    "  - **Interpretation:** Measures the average magnitude of the errors, giving more weight to larger errors.\n",
    "\n",
    "- **Mean Squared Error (MSE):**\n",
    "  - **Definition:** The average of the squared differences between actual and predicted values.\n",
    "  - **Interpretation:** Similar to RMSE but without the square root, providing a measure of the average squared error.\n",
    "\n",
    "- **Mean Absolute Error (MAE):**\n",
    "  - **Definition:** The average of the absolute differences between actual and predicted values.\n",
    "  - **Interpretation:** Measures the average magnitude of the errors without considering their direction.\n",
    "\n",
    "- **Explanation:**\n",
    "  - The function calculates predicted playing times for games using a collaborative filtering model.\n",
    "  - It then compares the predicted playing times with the actual playing times for games the user has already played.\n",
    "  - RMSE, MSE, and MAE are computed to quantify the accuracy and performance of the recommendation model.\n",
    "  - The results are printed, and the function returns the computed MAE, RMSE, and MSE values.\n",
    "\n",
    "These evaluation metrics provide insights into how well the recommendation model is predicting playing times for games, with lower values indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ea1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(uid:int,\n",
    "              playing_time_df:pd.core.frame.DataFrame,\n",
    "              model: surprise.prediction_algorithms.matrix_factorization.SVD,\n",
    "              games_dict:dict\n",
    "             ):\n",
    "\n",
    "    #get the adjusted playing time for each game by this user\n",
    "    my_games=playing_time_df[playing_time_df.userId==uid]\n",
    "\n",
    "    already_played=dict(zip(my_games.Game,my_games.Scaled_Value))\n",
    "\n",
    "    pred_dict={}# store predicted playing time\n",
    "\n",
    "    for game in games_dict: # for every game \n",
    "\n",
    "        pred_dict[game]=model.predict(uid = uid,iid = game).est\n",
    "        \n",
    "    actual,pred=[],[]\n",
    "    \n",
    "    for mid in already_played: \n",
    "        actual.append(already_played[mid])\n",
    "        pred.append(pred_dict[mid])\n",
    "    \n",
    "    rmse = mean_squared_error(actual,pred,squared=False)\n",
    "    mse = mean_squared_error(actual,pred,squared=True)\n",
    "    mae = mean_absolute_error(actual,pred)\n",
    "    \n",
    "    print('Recommendations MAE: ', round(mae,4))\n",
    "    print('Recommendations RMSE: ', round(rmse,4))\n",
    "    print('Recommendations MSE: ', round(mse,4))\n",
    "    \n",
    "    return mae,rmse,mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7cfb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations MAE:  0.0922\n",
      "Recommendations RMSE:  0.1756\n",
      "Recommendations MSE:  0.0308\n"
     ]
    }
   ],
   "source": [
    "mae,rmse,mse = evaluate_recommendations(109205612,\n",
    "              games_df_mt,\n",
    "              svd,\n",
    "              games_dict\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
