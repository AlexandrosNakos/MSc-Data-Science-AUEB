{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796e01ae",
   "metadata": {},
   "source": [
    "# Scraping Rate Your Music Reviews\n",
    "\n",
    "> *Advanced Customer Analytics*  \n",
    "> *MSc in Data Science, Department of Informatics*  \n",
    "> *Athens University of Economics and Business*\n",
    "\n",
    "---\n",
    "\n",
    "Select an English-speaking website that hosts customer reviews on products (or services, businesses, movies, events, etc.). Make sure that the website includes a free-text search box that users can use to search for products. Create a first Python notebook with a function called <code>scrape()</code>. The function should accept as a parameter a query (a word or short phrase). The function should then use ***selenium*** to (1) submit the query to the website's search box and retrieve the list of matching products, and (2) access the first product on the. list and download all its reviews into a csv file. For each review, the function should get the text, the rating and the date. One line per review, 3 fields per line.\n",
    "\n",
    "---\n",
    "\n",
    "##### *Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a611e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import re, time,csv\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9db2d",
   "metadata": {},
   "source": [
    "##### *Function to clear a possible cookie overlay*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d780380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_consent_overlay():\n",
    "    \n",
    "    try: # try to get the consent button in case there is a coukie overlay  \n",
    "        consent_button = driver.find_element(by = By.CSS_SELECTOR, \n",
    "                                             value='button[class=\"fc-button fc-cta-consent fc-primary-button\"]')\n",
    "        consent_button.click()\n",
    "    except NoSuchElementException as e: # continue if there is no overlay\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d392b",
   "metadata": {},
   "source": [
    "##### *Function to get the reviews from each page*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ebe692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_reviews(writer: csv.writer):\n",
    "    \"\"\"\n",
    "    Extracts reviews from a webpage and writes them to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - writer: CSV writer object to handle writing rows to a CSV file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        reviews = driver.find_elements(by=By.CSS_SELECTOR, value='div[class=\"review\"]')\n",
    "    except:\n",
    "        print('No Review Found In This Page')\n",
    "\n",
    "    for review in reviews:\n",
    "\n",
    "        valid = False\n",
    "\n",
    "        content, rating, date = 'NA', 'NA', 'NA'\n",
    "\n",
    "        try:\n",
    "            content_box = review.find_element(by=By.CSS_SELECTOR, value='span[itemprop=\"description\"]')\n",
    "            content = content_box.text\n",
    "            if content != '' and content != ' ':\n",
    "                if detect(content) == 'en':\n",
    "                    valid = True\n",
    "        except NoSuchElementException as e:  # review content could not be found\n",
    "            print('Could not Extract Review Content')\n",
    "\n",
    "        try:\n",
    "            rating_box = review.find_element(by=By.CSS_SELECTOR, value='span[class=\"review_rating\"]')\n",
    "            rating = rating_box.get_attribute('content')\n",
    "        except NoSuchElementException as e:  # review rating could not be found\n",
    "            print('Could not Extract Review Rating')\n",
    "\n",
    "        try:\n",
    "            date_box = review.find_element(by=By.CSS_SELECTOR, value='span[class=\"review_date\"]')\n",
    "            date = date_box.get_attribute('content')\n",
    "        except NoSuchElementException as e:  # review date could not be found\n",
    "            print('Could not Extract Review Date')\n",
    "\n",
    "        # write a new row if review content is not empty\n",
    "        if valid == True:\n",
    "            writer.writerow([rating, date, content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd0b04",
   "metadata": {},
   "source": [
    "##### *Function to scrape the reviews*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bca608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(query: str, delay: int = 2):\n",
    "    \"\"\"\n",
    "    Scrapes reviews for a given query from the RateYourMusic website.\n",
    "\n",
    "    Parameters:\n",
    "    - query: The search term for reviews.\n",
    "    - delay: Time delay in seconds between page navigation.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new CSV writer for the story links\n",
    "    fw = open('The Car Reviews.csv', 'w', encoding=\"utf-8\")\n",
    "    writer = csv.writer(fw, lineterminator='\\n')\n",
    "    writer.writerow(['Rating', 'Date', 'Content'])\n",
    "\n",
    "    url = 'https://rateyourmusic.com/search?searchterm=' + query\n",
    "    driver.get(url)\n",
    "\n",
    "    clear_consent_overlay()\n",
    "\n",
    "    # get all the links from the results page\n",
    "    album_links = driver.find_elements(By.LINK_TEXT, 'The Car')\n",
    "\n",
    "    try:\n",
    "        driver.get(album_links[0].get_attribute('href'))\n",
    "    except IndexError:\n",
    "        print('Could Not Get Any Links')\n",
    "\n",
    "    clear_consent_overlay()\n",
    "\n",
    "    page_cnt = 1  # keep track of page count\n",
    "\n",
    "    while True:\n",
    "\n",
    "        print('page', page_cnt)  # print the current page count\n",
    "\n",
    "        page_cnt += 1  # increment\n",
    "\n",
    "        get_page_reviews(writer)  # get reviews from the current page\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "        clear_consent_overlay()\n",
    "\n",
    "        try:  # check whether there is a next button\n",
    "            # three navigation bars with the same functionality, we always get the first\n",
    "            next_button = driver.find_elements(by=By.CSS_SELECTOR, value='a[class=\"navlinknext\"]')[0]\n",
    "            driver.get(next_button.get_attribute('href'))  # go to the next review page\n",
    "        except IndexError:\n",
    "            print('No more review pages')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f861a",
   "metadata": {},
   "source": [
    "##### *Execution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721376bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1\n",
      "page 2\n",
      "page 3\n",
      "page 4\n",
      "page 5\n",
      "page 6\n",
      "page 7\n",
      "page 8\n",
      "page 9\n",
      "page 10\n",
      "page 11\n",
      "page 12\n",
      "page 13\n",
      "page 14\n",
      "No more review pages\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "\n",
    "scrape('arctic%20monkeys%20the%20car&searchtype=')\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
